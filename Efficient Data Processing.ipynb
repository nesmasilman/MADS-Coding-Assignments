{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All).\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please add your name and University of Michagan uniqname here...\n",
    "\n",
    "NAME = ''\n",
    "UMICH_UNIQNAME = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "828bc331fb4b474c4dc318c79e21c858",
     "grade": false,
     "grade_id": "cell-5a2075c6fc8553e4",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "version = \"v2.3.060120\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "409f037ad73b24de5435ca5034e81b2f",
     "grade": false,
     "grade_id": "cell-7dd8dd131b0c6a5d",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# SIADS 515 Week 4 Homework (HW4)\n",
    "\n",
    "## Background\n",
    "\n",
    "The motivation for this assignment is to **improve the efficiency of code** that finds the similarity between any two given documents.  There are many ways to calculate similarity (or distance) between two documents, but the most effective way is to represent each document as a multi-dimensional vector where each dimension corresponds to a word, and the value along that dimension is the number of times that word occurs in a document.  Let's take a look at a simplified case where we only have two dimensions:\n",
    "\n",
    "![](assets/CosineDistanceSimilarity.png)\n",
    "\n",
    "In the above diagram, Item 1 and Item 2 refer to two documents.  The angle between them (ð›³) can range from -180 to +180 degrees.  The cosine of angles, in this case, has a nice property in that the cosine of an angle of 0 degrees is 1, the cosine of an angle of 90 degrees is 0, and the cosine of an angle of 180 degrees is -1.  In other words, the cosine of the angle between the vector representation of a document behaves much like a correlation coefficient.  A cosine of 1 indicates the documents are identical, a cosine of 0 indicates the documents are independent of each other, and a cosine of -1 indicates the documents are \"opposites\" (note: the latter requires a specific setup that is beyond the scope of this course).\n",
    "\n",
    "Your task, for this assignment, is to improve the efficiency of the code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "523ea2670f08a68ece190b1283069754",
     "grade": false,
     "grade_id": "cell-4775a39fe80a7d8a",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Steps\n",
    "\n",
    "1. Run the notebook as it is.\n",
    "1. Study each function in the code, making notes to yourself in preparation for the next step.  \n",
    "1. Annotate each function with a detailed description of what the input and output parameters are.  Provide a brief description, in your own words, of what each function does.  Use docstrings ([PEP-257](https://www.python.org/dev/peps/pep-0257/)) to document the code.\n",
    "1. Make changes to the code to improve its efficiency. \n",
    "\n",
    "Note\n",
    "  - You may [refactor](https://en.wikipedia.org/wiki/Code_refactoring) to combine functions or make other changes if that helps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# docdist1.py\n",
    "# Original author: Ronald L. Rivest\n",
    "# Some adaptation by Chris Teplovs and Kevyn Collins-Thompson\n",
    "#\n",
    "#\n",
    "# This program computes the \"distance\" between two text files\n",
    "# as the angle between their word frequency vectors.\n",
    "#\n",
    "# For each input file, a word-frequency vector is computed as follows:\n",
    "#    (1) the specified file is read in\n",
    "#    (2) it is converted into a list of alphanumeric \"words\"\n",
    "#        Here a \"word\" is a sequence of consecutive alphanumeric\n",
    "#        characters.  Non-alphanumeric characters are treated as blanks.\n",
    "#        Case is not significant.\n",
    "#    (3) for each word, its frequency of occurrence is determined\n",
    "#    (4) the word/frequency lists are sorted into order alphabetically\n",
    "#\n",
    "# The \"distance\" between two vectors is the angle between them.\n",
    "# If x = (x1, x2, ..., xn) is the first vector (xi = freq of word i)\n",
    "# and y = (y1, y2, ..., yn) is the second vector,\n",
    "# then the angle between them is defined as:\n",
    "#    d(x,y) = arccos(inner_product(x,y) / (norm(x)*norm(y)))\n",
    "# where:\n",
    "#    inner_product(x,y) = x1*y1 + x2*y2 + ... xn*yn\n",
    "#    norm(x) = sqrt(inner_product(x,x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "    # math.acos(x) is the arccosine of x.\n",
    "    # math.sqrt(x) is the square root of x.\n",
    "\n",
    "import string\n",
    "    # string.join(words,sep) takes a given list of words,\n",
    "    #    and returns a single string resulting from concatenating them\n",
    "    #    together, separated by the string sep .\n",
    "    # string.lower(word) converts word to lower-case\n",
    "\n",
    "import sys\n",
    "    # sys.exit() allows us to quit (if we can't read a file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################\n",
    "# Operation 1: read a text file ##\n",
    "##################################\n",
    "def read_file(filename):\n",
    "    ###    Read the text file with the given filename;\n",
    "    ###     return a list of the lines of text in the file.\n",
    "    try:\n",
    "        fp = open(filename)\n",
    "        L = fp.readlines()\n",
    "    except IOError as excObj:\n",
    "        print(str(excObj))\n",
    "        print(\"Error opening or reading input file: \" + filename)\n",
    "        sys.exit()\n",
    "    return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################\n",
    "# Operation 2: split the text lines into words ##\n",
    "#################################################\n",
    "def get_words_from_line_list(L):\n",
    "    ### Parse the given list L of text lines into words.\n",
    "    ### Return list of all words found.\n",
    "\n",
    "    word_list = []\n",
    "    for line in L:\n",
    "        words_in_line = get_words_from_string(line)\n",
    "        word_list = word_list + words_in_line\n",
    "    return word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_words_from_string(line):\n",
    "    ### Return a list of the words in the given input string,\n",
    "    ### converting each word to lower-case.\n",
    "    ###\n",
    "    ### Input:  line (a string)\n",
    "    ### Output: a list of strings\n",
    "    ###          (each string is a sequence of alphanumeric characters)\n",
    "\n",
    "    word_list = []          # accumulates words in line\n",
    "    character_list = []     # accumulates characters in word\n",
    "    for c in line:\n",
    "        if c.isalnum():\n",
    "            character_list.append(c)\n",
    "        elif len(character_list)>0:\n",
    "            word = str.join(\"\", character_list)\n",
    "            word = str.lower(word)\n",
    "            word_list.append(word)\n",
    "            character_list = []\n",
    "    if len(character_list)>0:\n",
    "        word = str.join(\"\", character_list)\n",
    "        word = str.lower(word)\n",
    "        word_list.append(word)\n",
    "    return word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################\n",
    "# Operation 3: count frequency of each word ##\n",
    "##############################################\n",
    "def count_frequency(word_list):\n",
    "    ### Return a list giving pairs of form: (word,frequency)\n",
    "\n",
    "    L = []\n",
    "    for new_word in word_list:\n",
    "        for entry in L:\n",
    "            if new_word == entry[0]:\n",
    "                entry[1] = entry[1] + 1\n",
    "                break\n",
    "        else:\n",
    "            L.append([new_word,1])\n",
    "    return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################\n",
    "# Operation 4: sort words into alphabetic order             ###\n",
    "###############################################################\n",
    "def insertion_sort(A):\n",
    "\n",
    "    ### Sort list A into order, in place.\n",
    "    ###\n",
    "    ### From Cormen/Leiserson/Rivest/Stein,\n",
    "    ### Introduction to Algorithms (second edition), page 17,\n",
    "    ### modified to adjust for fact that Python arrays use\n",
    "    ### 0-indexing.\n",
    "\n",
    "    for j in range(len(A)):\n",
    "        key = A[j]\n",
    "        # insert A[j] into sorted sequence A[0..j-1]\n",
    "        i = j-1\n",
    "        while i>-1 and A[i]>key:\n",
    "            A[i+1] = A[i]\n",
    "            i = i-1\n",
    "        A[i+1] = key\n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "## compute word frequencies for input file ##\n",
    "#############################################\n",
    "def word_frequencies_for_file(filename,verbose=False):\n",
    "\n",
    "    ### Return alphabetically sorted list of (word,frequency) pairs\n",
    "    ### for the given file.\n",
    "\n",
    "    line_list = read_file(filename)\n",
    "    word_list = get_words_from_line_list(line_list)\n",
    "    freq_mapping = count_frequency(word_list)\n",
    "    insertion_sort(freq_mapping)\n",
    "    if verbose:\n",
    "        print(\"File\",filename,\":\", len(line_list),\"lines,\", len(word_list),\"words,\", len(freq_mapping),\"distinct words\")\n",
    "\n",
    "    return freq_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inner_product(L1,L2):\n",
    "\n",
    "    ### Inner product between two vectors, where vectors\n",
    "    ### are represented as alphabetically sorted (word,freq) pairs.\n",
    "\n",
    "    ### Example: inner_product([[\"and\",3],[\"of\",2],[\"the\",5]],\n",
    "    ###                        [[\"and\",4],[\"in\",1],[\"of\",1],[\"this\",2]]) = 14.0\n",
    "\n",
    "    sum = 0.0\n",
    "    i = 0\n",
    "    j = 0\n",
    "    while i<len(L1) and j<len(L2):\n",
    "        # L1[i:] and L2[j:] yet to be processed\n",
    "        if L1[i][0] == L2[j][0]:\n",
    "            # both vectors have this word\n",
    "            sum += L1[i][1] * L2[j][1]\n",
    "            i += 1\n",
    "            j += 1\n",
    "        elif L1[i][0] < L2[j][0]:\n",
    "            # word L1[i][0] is in L1 but not L2\n",
    "            i += 1\n",
    "        else:\n",
    "            # word L2[j][0] is in L2 but not L1\n",
    "            j += 1\n",
    "    return sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_angle(L1,L2):\n",
    "\n",
    "    ### The input is a list of (word,freq) pairs, sorted alphabetically.\n",
    "    ### Return the angle between these two vectors.\n",
    "\n",
    "    numerator = inner_product(L1,L2)\n",
    "    denominator = math.sqrt(inner_product(L1,L1)*inner_product(L2,L2))\n",
    "    return numerator/denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def document_similarity(filename_1, filename_2, verbose=True):\n",
    "    \"\"\"DOCSTRING\"\"\"\n",
    "    sorted_word_list_1 = word_frequencies_for_file(filename_1, verbose)\n",
    "    sorted_word_list_2 = word_frequencies_for_file(filename_2, verbose)\n",
    "    cosine = vector_angle(sorted_word_list_1,sorted_word_list_2)\n",
    "    # Use f-strings; see https://realpython.com/python-f-strings/ for more information\n",
    "    if verbose:\n",
    "        print(f\"The cosine between the documents is {cosine : 0.6f}.\")\n",
    "        print(f\"The angle between the documents is {math.acos(cosine) : 0.6f} radians or {math.acos(cosine)*180/math.pi : .0f} degrees.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_similarity('assets/short.t1.txt','assets/short.t2.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perfomance of short text cases\n",
    "\n",
    "%timeit document_similarity('assets/short.t1.txt','assets/short.t2.txt', verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perfomance of long text cases\n",
    "\n",
    "# Note that this will take a very long time to run before you make your optimizations.\n",
    "#   Use Kernel --> Interupt in the Jupyter menu to stop execution.\n",
    "\n",
    "# Comment this out before submitting to get fast results from the autograder...\n",
    "\n",
    "%timeit document_similarity('assets/t1.verne.txt', 'assets/t2.bobsey.txt', verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perfomance of very long text cases\n",
    "\n",
    "# Note that this will take a very long time to run before you make your optimizations.\n",
    "#   Use Kernel --> Interupt in the Jupyter menu to stop execution.\n",
    "\n",
    "# Comment this out before submitting to get fast results from the autograder...\n",
    "\n",
    "# %timeit document_similarity('assets/t5.churchill.txt', 'assets/t8.shakespeare.txt', verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "b2efa089c3ef418eaec2edb0d5260401",
     "grade": true,
     "grade_id": "cell-1a-63aea205c14ed",
     "locked": true,
     "points": 20,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Result validation\n",
    "# 20 points\n",
    "\n",
    "# This check verifies that your results are correct for the short text cases.\n",
    "\n",
    "sorted_word_list_1 = word_frequencies_for_file('assets/short.t1.txt', verbose=False)\n",
    "sorted_word_list_2 = word_frequencies_for_file('assets/short.t2.txt', verbose=False)\n",
    "cosine = vector_angle(sorted_word_list_1,sorted_word_list_2)\n",
    "\n",
    "def close_match(a, b):\n",
    "    return round(float(a), 3) == round(float(b), 3)\n",
    "\n",
    "assert len(sorted_word_list_1) == 772\n",
    "assert len(sorted_word_list_2) == 334\n",
    "\n",
    "assert close_match(vector_angle(sorted_word_list_1,sorted_word_list_2), 0.713)\n",
    "assert close_match(math.acos(cosine), 0.778)  # Documents angle in radians\n",
    "assert close_match(math.acos(cosine)*180/math.pi, 44.559)  # Documents angle in degrees\n",
    "\n",
    "# There are no hidden autograder tests in this cell."
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "schema_names": [
    "mads_efficient_data_processing_v2_assignment4"
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
